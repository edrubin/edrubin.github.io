---
title: "Updating Intuition on Attenuation Bias"
output:
  html_document:
    toc: true
    number_sections: false
    toc_float:
      collapsed: false
      smooth_scroll: true
---

Sunday, 26 December 2017

<br>

# Loken and Gelman

In a recent [_Science_ paper](http://science.sciencemag.org/content/355/6325/584.full), Eric Loken and Andrew Gelman discuss an interesting statistical nuance relevant to measurement error. Loken and Gelman begin by pointing out statisticians/econometricians/people with data and computers have the mindset that measurement error in one of our covariates biases our point estimates toward zero—the infamous _attenuation bias_. Pushing this attenuation-based mindset further, researchers infer that a statistically significant point estimate would be even larger _in the absence_ of measurement error. Loken and Gelman  that this second logical leap is not, in fact, logical. Why? While attenuation bias is a real thing, once we begin conditioning on statistically significant results, we add a second dimension that we must consider: power. In settings with low power—_e.g._, small $N$ and subtantial variance—in order to "achieve" a statistically significant result, the point estimate must be quite large. Thus, the _attenuation effect_ may be reversed by a _low-power_ effect. The big idea here is that conditioning on significant results—a very real thing in the presence of p-hacking and publication bias—changes the behavior of something we all thought we understood—measurement error and attentuation bias.

Loken and Gelman's takeaway?
<br> "A key point for practitioners is that surprising results from small studies should not be defended by saying that they would have been even better with improved measurement."

# Simulation

I thought it would be fun to replicate the results in a simple simulation.


## My R setup

```{R setup, message = F}
# Packages
library(data.table)
library(magrittr)
library(parallel)
library(ggplot2)
library(viridis)
# My ggplot2 theme
theme_ed <- theme(
  legend.position = "bottom",
  panel.background = element_rect(fill = NA),
  # panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey95", size = 0.3),
  panel.grid.major = element_line(color = "grey95", size = 0.3),
  panel.grid.minor = element_line(color = "grey95", size = 0.3),
  legend.key = element_blank())
# Set seed
set.seed(12345)
```

## Function: Generating data

One of Loken and Gelman's big points is that sample size (specifically, power) matters for attenuation bias, once we start conditioning on statistically significant results. So let's write a function that generates a sample of size `n` for a simple linear regression. The function will also take as inputs the true intercept `alpha` and the true slope coefficient `beta`. For simplicity, we will generate each variable from a standard normal distribution. Finally, the function will accept a third parameter `gamma` that dictates the degree of measurement error in our covariance.

Formally, the population data-generating process is

$$ y_i = \alpha + \beta x_i + \varepsilon_i $$

but instead of observing $x_i$, the researcher observes

$$ w_i = x_i + \gamma u_i $$

where $\gamma u_i$ is the "noise" that we add to $x_i$ to generate measurement error. Again, we will assume $u_i$ comes from a standard normal distribution.

```{R fun:sim_data}
sim_data <- function(n, alpha, beta, gamma) {
  # Generate x, e (disturbance), and u
  gen_dt <- data.table(
    x = rnorm(n),
    e = rnorm(n),
    u = rnorm(n)
    )
  # Calculate w and y
  gen_dt[, `:=`(
    w = x + gamma * u,
    y = alpha + beta * x + e
    )]
  # Return the data
  return(gen_dt)
}
```

## Function: Running the simulation

In the simulation, we will regress $\mathbf{y}$ on $\mathbf{w}$ (and a column of ones) and then calculate the standard errors, _t_ statistics, and _p_-values. The `base` installation's `lm()` function works just fine in this context. We'll ignore inference/estimates for the intercept.

```{R fun:sim_reg}
sim_reg <- function(data) {
  # Run the regression without measurement error
  reg_clean <- lm(y ~ x, data) %>% summary() %>% coef() %>%
    # Grab the second row
    extract(2, ) %>%
    # Force to matrix then to data.table
    matrix(nrow = 1) %>% data.table()
  # Run the regression with measurement error
  reg_noise <- lm(y ~ w, data) %>% summary() %>% coef() %>%
    # Grab the second row
    extract(2, ) %>%
    # Force to matrix then to data.table
    matrix(nrow = 1) %>% data.table()
  reg_dt <- rbindlist(list(reg_clean, reg_noise))
  # Set names
  setnames(reg_dt, c("est_coef", "se", "t_stat", "p_value"))
  # Add column for type of regression
  reg_dt[, type := c("clean", "noise")]
  # Return reg_dt
  return(reg_dt)
}
```

Now we'll make a wrapper function that applies `sim_data()` and `sim_reg()`, effectively running a single iteration of the simulation.
```{R fun:sim_one}
sim_one <- function(n, alpha, beta, gamma) {
  # Run the regression function on simulated data
  one_dt <- sim_reg(data = sim_data(n, alpha, beta, gamma))
  # Add the sample size
  one_dt[, n := n]
  # Return the results
  return(one_dt)
}
```

And now a function to run the simulation `n_iter` times for the given set of parameters (`n_iter` times for each sample size `n`).
```{R fun:sim_run}
sim_run <- function(n_iter, n, alpha, beta, gamma, n_cores = 4) {
  # Run n_iter
  sim_dt <- mclapply(
    X = rep(n, each = n_iter),
    FUN = sim_one,
    alpha = alpha, beta = beta, gamma = gamma,
    mc.cores = n_cores) %>% rbindlist()
  # Record the parameter values
  sim_dt[, `:=`(alpha = alpha, beta = beta, gamma = gamma)]
  # Return the simulation results
  return(sim_dt)
}
```

## Run the simulation, three sample sizes

Now let's actually run the simulation. Let's start with three sample sizes: 30, 100, 1000.

```{R run simulation, cache = T}
the_sim <- sim_run(
  n_iter = 1e4,
  n = c(30, 100, 1e3),
  alpha = 10,
  beta = 1,
  gamma = 0.25,
  n_cores = 4)
```

## Examine results, three sample sizes

A few quick changes for plotting/description:
```{R add variables}
# Add a variable for a significant result (0.05 level)
the_sim[, `:=`(
  sig = p_value < 0.05,
  n_fac = factor(n, ordered = T)
  )] %>% invisible()
```

Examine the results:

```{R describe simulation}
# Compare means by sample size
the_sim[, list(
  mean_coef = mean(est_coef),
  pct_sample = .N/1e4
  ), by = n]
# Compare means by sample size and significance
the_sim[, list(
  mean_coef = mean(est_coef),
  pct_sample = .N/1e4
  ), by = .(n, sig)]
# Compare pct. of coef. > 1, by sample size and significance
the_sim[, list(
  pct_exceed = mean(est_coef > 1),
  pct_sample = .N/1e4
  ), by = .(n, sig)]
  ```

Let's plot the distribution of significant coefficient estimates.
```{R plot dist coef, fig.width = 8, fig.height = 8}
ggplot(the_sim[sig == T], aes(est_coef)) +
  geom_density(aes(fill = n_fac),
    alpha = 0.7, size = 0.1, color = "grey50") +
  geom_vline(xintercept = 1, color = "grey30", linetype = 2) +
  xlab(expression(paste(widehat(beta), " (estimated coefficient)"))) +
  ylab("Density") +
  ggtitle("Distribution of estimated coefficients, by sample size",
    subtitle = "in the presence of measurement error") +
  theme_ed +
  scale_fill_viridis("Sample size:", discrete = T, direction = -1)
```

We can also make a nice comparison of the estimated coefficient compared with the "ideal" estimate (without measurement error), following Loken and Gelman's figure.

<!-- TODO -->

## Run the simulation, many sample sizes

Now let's run the simulation for a bunch of sample sizes. __Note:__ You may want to drop the number of iterations per sample size to 1,000 (from 10,000) so it finishes in a reasonable amount of time.

```{R run simulation many n, cache = T}
big_sim <- sim_run(
  n_iter = 1e4,
  n = c(10, seq(50, 3e3, 50)),
  alpha = 10,
  beta = 1,
  gamma = 0.25,
  n_cores = 4)
```
